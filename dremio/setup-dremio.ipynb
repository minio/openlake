{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682057dd",
   "metadata": {},
   "source": [
    "# Setup Dremio in Kubernetes Cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11710f7a",
   "metadata": {},
   "source": [
    "### What is Dremio?\n",
    "\n",
    "Dremio is an open-source, distributed analytics engine designed for high-performance analytics on data lakes. It provides a simple, self-service interface for data exploration, transformation, and collaboration. Dremio's architecture is built on top of Apache Arrow, a high-performance columnar memory format, and leverages the Parquet file format for efficient storage. By combining these technologies, Dremio enables users to query data from various sources, including Hadoop, NoSQL databases, and cloud storage, without the need for data movement or copies.\n",
    "\n",
    "There are several reasons why Dremio has gained popularity among data professionals:\n",
    "\n",
    "* **Self-service data exploration and transformation**: Dremio empowers data analysts and scientists to explore, clean, and transform data using SQL or visual interfaces. This self-service model reduces the burden on IT teams and speeds up the data analysis process.\n",
    "\n",
    "* **Unified data access**: Dremio connects to a wide range of data sources, allowing users to query data from multiple systems simultaneously. This unified access simplifies data management and promotes collaboration between teams.\n",
    "\n",
    "* **High-performance queries**: By leveraging Apache Arrow and columnar storage, Dremio delivers fast query performance on large datasets. Additionally, it employs advanced techniques like predicate pushdown and column pruning to optimize queries further.\n",
    "\n",
    "* **Scalability**: Dremio's distributed architecture can scale horizontally to accommodate growing data volumes and concurrent user workloads. This scalability ensures that Dremio can handle the demands of even the largest enterprises.\n",
    "\n",
    "* **Security and governance**: Dremio supports robust security features, including data access controls, encryption, and integration with enterprise security solutions like LDAP and Active Directory. These features help organizations maintain compliance and protect sensitive data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a91e22",
   "metadata": {},
   "source": [
    "## Setup Dremio OSS in Kubernetes\n",
    "\n",
    "\n",
    "To deploy Dremio in a Kubernetes cluster, we can use Helm charts. Helm is a package manager for Kubernetes that helps us to deploy, manage, and upgrade applications in a Kubernetes cluster. Helm charts provide a set of templates and configurations that define how an application should be deployed in Kubernetes.\n",
    "\n",
    "In this scenario, we will use the Dremio OSS (Open Source Software) image to deploy 1 Master, 3 Executors and 3 Zookeepers. The Master node is responsible for coordinating the cluster, while the Executors are responsible for processing the data. By deploying multiple Executors, we can parallelize the data processing and improve the performance of our cluster.\n",
    "\n",
    "To store the data in a distributed manner, we will use MinIO bucket as the distributed storage. MinIO is a high-performance, distributed object storage system that is designed for cloud-native applications. Whenever new files are uploaded to Dremio, they will be stored in the MinIO bucket. This allows us to store and process large amounts of data in a scalable and distributed manner.\n",
    "\n",
    "### Prerequisites\n",
    "To Follow the instructions in the Notebook below you will need,\n",
    "* A Kubernetes cluster. You can use Minikube to set up a local Kubernetes cluster on your machine\n",
    "* Helm, the package manager for Kubernetes. You can follow this guide to install Helm on your machine.\n",
    "* A MinIO server running on bare metal or kubernetes. You can follow [this](https://min.io/docs/minio/linux/operations/installation.html#install-and-deploy-minio) guide to install MinIO on bare metal or [this](https://min.io/docs/minio/kubernetes/upstream/index.html) guide to install MinIO on Kubernetes or you can use [play server](https://play.min.io/) for testing purposes.\n",
    "* A MinIO client (mc) to access the MinIO server. You can follow [this](https://docs.min.io/docs/minio-client-quickstart-guide.html) guide to install mc on your machine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e63b72",
   "metadata": {},
   "source": [
    "### Create MinIO bucket\n",
    "\n",
    "Let's create a MinIO bucket `openlake/dremio` which will be used by Dremio as the distributed storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mc mb play/openlake\n",
    "!mc mb play/openlake/dremio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20bb007",
   "metadata": {},
   "source": [
    "### Clone dremio-cloud-tools repo\n",
    "\n",
    "we will use the helm charts from this repo to setup Dremio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ebd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/dremio/dremio-cloud-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc85de",
   "metadata": {},
   "source": [
    "We will use the `demio_v2` version of the charts, we will uses the `values.minio.yaml` file in the current directory to setup Dremio. Lets copy the YAML to `dremio-cloud-tools/charts/dremio_v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp charts/values.minio.yaml dremio-cloud-tools/charts/dremio_v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba255a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd dremio-cloud-tools/charts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5a6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls dremio_v2 #you should see values.minio.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f244a9",
   "metadata": {},
   "source": [
    "### Install Dremio using Helm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca8547",
   "metadata": {},
   "outputs": [],
   "source": [
    "!helm install dremio dremio_v2 -f dremio_v2/values.minio.yaml --namespace dremio --create-namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963f392",
   "metadata": {},
   "source": [
    "Above command will install Dremio released names `dremio` in the namespace `dermio` and it creates the new namespace `dremio`. \n",
    "\n",
    "Note: Make sure to update you Minio Endpoint, access key and secret key in the `values.minio.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c8046",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n dremio get pods # after the helm setup is complete it takes sometime for the pods to be up and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n dremio get svc # List all the services in namespace dremio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mc ls play/openlake/dremio # we should see new prefixes being created that Dremio will use later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15738c80",
   "metadata": {},
   "source": [
    "### Login to Dremio\n",
    "\n",
    "To login to Dremio lets port `dremio-client` service to our localhost. After executing the below command goto http://localhost:9047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n dremio port-forward svc/dremio-client 9047 # stop the cell once you are done exploring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3190a4b5",
   "metadata": {},
   "source": [
    "You will need to setup a new user on your first time launching Dremio\n",
    "\n",
    "![Spark UI](./img/login-screen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909326c",
   "metadata": {},
   "source": [
    "Once we have setup the user we will be greeted with a welcome page. To keep this workflow simple let's upload a sample dataset to Dremio that is included in the repo `data/nyc_taxi_small.csv` and start querying it.\n",
    "\n",
    "We can upload `nyc_taxi_small.csv` by clicking on the `+` at the top right corner of the home page, as shown below\n",
    "![Add](./img/add.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bae733",
   "metadata": {},
   "source": [
    "Dremio will automatically parse the CSV and gives the recommended formatting as shown below, we will proceed further.\n",
    "![Format](./img/format.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mc ls --summarize --recursive openlake/dremio/uploads # you will see the CSV file uploaded in to the MinIO bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e53a8",
   "metadata": {},
   "source": [
    "We will be taken to the SQL query Console where we can start executing queries, here is 2 sample queries that you can try executing\n",
    "\n",
    "```sql\n",
    "SELECT count(*) FROM nyc_taxi_small;\n",
    "\n",
    "SELECT * FROM nyc_taxi_small;\n",
    "```\n",
    "\n",
    "Paste the above in the console and click `Run`, you see something like below\n",
    "\n",
    "![console](./img/console.png)\n",
    "\n",
    "You can click on `Query1` tab to see the number of Rows in the dataset \n",
    "\n",
    "![console-query1](./img/console1.png)\n",
    "\n",
    "You can click on `Query2` tab to see the number of Rows in the dataset \n",
    "![console-query2](./img/console2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a484e5",
   "metadata": {},
   "source": [
    "Now that we have end-to-end Dremio workflow working, let us take a look at `values.minio.yaml` to see what configurations were setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa2e65",
   "metadata": {},
   "source": [
    "## Deployment Walkthrough\n",
    "\n",
    "\n",
    "Now let's take a deepdive at the `values.minio.yaml` file to see some of the modifcations done to `distStorage` section\n",
    "\n",
    "```yaml\n",
    "distStorage:\n",
    "  aws:\n",
    "    bucketName: \"openlake\"\n",
    "    path: \"/dremio\"\n",
    "    authentication: \"accessKeySecret\"\n",
    "    credentials:\n",
    "     accessKey: \"minioadmin\"\n",
    "     secret: \"minioadmin\"\n",
    "\n",
    "    extraProperties: |\n",
    "     <property>\n",
    "       <name>fs.s3a.endpoint</name>\n",
    "       <value>play.min.io</value>\n",
    "     </property>\n",
    "     <property>\n",
    "       <name>fs.s3a.path.style.access</name>\n",
    "       <value>true</value>\n",
    "     </property>\n",
    "     <property>\n",
    "       <name>dremio.s3.compat</name>\n",
    "       <value>true</value>\n",
    "     </property>\n",
    "```\n",
    "\n",
    "We set the `distStorage` to `aws` and the name of the bucket is `openlake` and all the storage for Dremio will be under the prefix `dremio` (aka `s3://openlake/dremio`). We also need to add `extraProperties` since we are using MinIO to specify the Endpoint. We also need to add 2 additional properties in order to make Dremio work with MinIO `fs.s3a.path.style.access` need to be set to `true` and `dremio.s3.compat` to `true` so that dremio knows this is an S3 compatabile object store.\n",
    "\n",
    "Apart from this we can customize multiple other configurations like `executor` CPU, Memory usage depending on the K8s cluster capacity. We can also specify how many executors we need depending upon the size of workloads Dremio is going to handel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d109ec",
   "metadata": {},
   "source": [
    "Overall till now we have seen how to Deploy Dremio in K8s cluster and use MinIO as the distributed storage. We also saw how to upload sample dataset to Dremio and start querying it. We have just touched the tip of the iceberg ðŸ˜œ, in the following Notebook we will see how to manage `Apache Iceberg` table that was created by processing engine like Spark like shown [here](../spark/spark-iceberg-minio.ipynb) without any hassel and how to access data that you already have in MinIO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
